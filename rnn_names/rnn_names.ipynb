{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent neural network for name classification\n",
    "Closely following this PyTorch [tutorial]( https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html) and https://www.youtube.com/watch?v=WEV61GmmPrk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import ALL_LETTERS, N_LETTERS\n",
    "from utils import load_data, letter_to_tensor, letter_to_index, line_to_tensor, random_training_example\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.combined_to_hidden = nn.Linear(input_size + hidden_size, \n",
    "                                            hidden_size)\n",
    "        self.combined_to_output = nn.Linear(input_size + hidden_size, \n",
    "                                            output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), dim=1)\n",
    "        hidden = self.combined_to_hidden(combined)\n",
    "        output = self.combined_to_output(combined)\n",
    "        output = self.softmax(output) \n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Vietnamese', 'German', 'English', 'Czech', 'Chinese', 'French', 'Russian', 'Spanish', 'Italian', 'Japanese', 'Portuguese', 'Irish', 'Korean', 'Dutch', 'Greek', 'Scottish', 'Arabic', 'Polish'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import load_data\n",
    "category_lines, all_categories = load_data()\n",
    "n_categories = len(all_categories)\n",
    "category_lines.keys()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 128\n",
    "rnn = RNN(N_LETTERS, hidden_size, n_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the category with the highest predicted value\n",
    "def category_from_output(output):\n",
    "    category_idx = torch.argmax(output).item()\n",
    "    return all_categories[category_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 18])\n",
      "torch.Size([1, 128])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Spanish'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run one step of the network for a single letter\n",
    "input = letter_to_tensor('A')\n",
    "hidden = torch.zeros(1, hidden_size)\n",
    "\n",
    "output, next_hidden = rnn(input, hidden)\n",
    "print(output.size())\n",
    "print(next_hidden.size())\n",
    "category_from_output(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 18])\n",
      "torch.Size([1, 128])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Spanish'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run one step of the network for a whole word\n",
    "input = line_to_tensor('Albert')\n",
    "hidden = rnn.init_hidden()\n",
    "\n",
    "output, next_hidden = rnn(input[0], hidden)\n",
    "print(output.size())\n",
    "print(next_hidden.size())\n",
    "category_from_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "learning_rate = 0.005\n",
    "optimizer = torch.optim.SGD(rnn.parameters(), learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One training step\n",
    "def train(line_tensor, category_tensor):\n",
    "    hidden = rnn.init_hidden()\n",
    "\n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "\n",
    "    loss = criterion(output, category_tensor)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return output, loss.item()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 1.0 Loss: 2.9231 Current prediction: Souza / Japanese WRONG (Portuguese)\n",
      "2000 2.0 Loss: 2.8666 Current prediction: Sun / Greek WRONG (Korean)\n",
      "3000 3.0 Loss: 2.7737 Current prediction: Coupe / Greek WRONG (French)\n",
      "4000 4.0 Loss: 2.7836 Current prediction: Lian / Irish WRONG (Chinese)\n",
      "5000 5.0 Loss: 2.7384 Current prediction: Esteves / Greek WRONG (Portuguese)\n",
      "6000 6.0 Loss: 2.6388 Current prediction: Schubert / Scottish WRONG (German)\n",
      "7000 7.000000000000001 Loss: 2.5188 Current prediction: Jacques / Portuguese WRONG (French)\n",
      "8000 8.0 Loss: 2.3471 Current prediction: Momotani / Italian WRONG (Japanese)\n",
      "9000 9.0 Loss: 2.0439 Current prediction: Castell / Spanish CORRECT\n",
      "10000 10.0 Loss: 2.9193 Current prediction: Peaper / German WRONG (English)\n",
      "11000 11.0 Loss: 2.3223 Current prediction: Plourde / English WRONG (French)\n",
      "12000 12.0 Loss: 1.3270 Current prediction: Ahn / Korean CORRECT\n",
      "13000 13.0 Loss: 1.6284 Current prediction: Nader / Arabic CORRECT\n",
      "14000 14.000000000000002 Loss: 1.3318 Current prediction: Guerra / Portuguese CORRECT\n",
      "15000 15.0 Loss: 1.4208 Current prediction: Gronchi / Italian CORRECT\n",
      "16000 16.0 Loss: 2.2420 Current prediction: Murphy / Portuguese WRONG (Scottish)\n",
      "17000 17.0 Loss: 1.1257 Current prediction: Pantelas / Greek CORRECT\n",
      "18000 18.0 Loss: 2.0572 Current prediction: Abbaticchio / Russian WRONG (Italian)\n",
      "19000 19.0 Loss: 2.1856 Current prediction: Adrov / Portuguese WRONG (Russian)\n",
      "20000 20.0 Loss: 2.0303 Current prediction: Travieso / Italian WRONG (Spanish)\n",
      "21000 21.0 Loss: 2.2828 Current prediction: Plamondon / Scottish WRONG (French)\n",
      "22000 22.0 Loss: 1.6505 Current prediction: Escarcega / Spanish CORRECT\n",
      "23000 23.0 Loss: 1.5173 Current prediction: Sai / Chinese WRONG (Vietnamese)\n",
      "24000 24.0 Loss: 1.1198 Current prediction: Puerta / Spanish CORRECT\n",
      "25000 25.0 Loss: 0.2706 Current prediction: Rogashkov / Russian CORRECT\n",
      "26000 26.0 Loss: 1.9791 Current prediction: Kratschmar / Russian WRONG (Czech)\n",
      "27000 27.0 Loss: 1.6670 Current prediction: Ritchie / Scottish CORRECT\n",
      "28000 28.000000000000004 Loss: 0.2004 Current prediction: Takishida / Japanese CORRECT\n",
      "29000 28.999999999999996 Loss: 1.2969 Current prediction: Antwerpen / Dutch CORRECT\n",
      "30000 30.0 Loss: 2.5664 Current prediction: Finnegan / Irish WRONG (English)\n",
      "31000 31.0 Loss: 0.8006 Current prediction: Kolovos / Greek CORRECT\n",
      "32000 32.0 Loss: 1.7079 Current prediction: O'Keefe / French WRONG (Irish)\n",
      "33000 33.0 Loss: 0.1030 Current prediction: Kunisada / Japanese CORRECT\n",
      "34000 34.0 Loss: 0.3185 Current prediction: Ichigawa / Japanese CORRECT\n",
      "35000 35.0 Loss: 1.8232 Current prediction: Haik / Arabic CORRECT\n",
      "36000 36.0 Loss: 0.3341 Current prediction: Poniros / Greek CORRECT\n",
      "37000 37.0 Loss: 2.1781 Current prediction: Avery / French WRONG (English)\n",
      "38000 38.0 Loss: 1.6828 Current prediction: Lobo / Portuguese CORRECT\n",
      "39000 39.0 Loss: 0.0790 Current prediction: Mayuzumi / Japanese CORRECT\n",
      "40000 40.0 Loss: 0.4850 Current prediction: Agdarov / Russian CORRECT\n",
      "41000 41.0 Loss: 0.8195 Current prediction: Lopez / Spanish CORRECT\n",
      "42000 42.0 Loss: 0.0230 Current prediction: Nakazawa / Japanese CORRECT\n",
      "43000 43.0 Loss: 0.7545 Current prediction: To / Vietnamese CORRECT\n",
      "44000 44.0 Loss: 3.0494 Current prediction: Maceachthighearna / Czech WRONG (Irish)\n",
      "45000 45.0 Loss: 1.8234 Current prediction: Vieth / Dutch WRONG (German)\n",
      "46000 46.0 Loss: 1.4939 Current prediction: Richard / French CORRECT\n",
      "47000 47.0 Loss: 2.2086 Current prediction: Schneider / German WRONG (Dutch)\n",
      "48000 48.0 Loss: 2.1892 Current prediction: Pelletier / Portuguese WRONG (French)\n",
      "49000 49.0 Loss: 0.1429 Current prediction: Quang / Vietnamese CORRECT\n",
      "50000 50.0 Loss: 0.3696 Current prediction: Davidson / Scottish CORRECT\n",
      "51000 51.0 Loss: 1.4053 Current prediction: Sokolof / Polish CORRECT\n",
      "52000 52.0 Loss: 1.7794 Current prediction: Johnstone / German WRONG (Scottish)\n",
      "53000 53.0 Loss: 0.1620 Current prediction: Kapsimalles / Greek CORRECT\n",
      "54000 54.0 Loss: 0.4877 Current prediction: Jung  / Korean CORRECT\n",
      "55000 55.00000000000001 Loss: 0.7013 Current prediction: Esteves / Portuguese CORRECT\n",
      "56000 56.00000000000001 Loss: 0.4816 Current prediction: Palmeiro / Portuguese CORRECT\n",
      "57000 56.99999999999999 Loss: 0.6502 Current prediction: Shammas / Arabic CORRECT\n",
      "58000 57.99999999999999 Loss: 3.3372 Current prediction: Raskob / Russian WRONG (German)\n",
      "59000 59.0 Loss: 5.7920 Current prediction: Collard / Irish WRONG (English)\n",
      "60000 60.0 Loss: 1.2642 Current prediction: Ocaskova / Czech CORRECT\n",
      "61000 61.0 Loss: 1.0141 Current prediction: Janin / Russian CORRECT\n",
      "62000 62.0 Loss: 1.3566 Current prediction: Nakadan / Arabic WRONG (Japanese)\n",
      "63000 63.0 Loss: 0.4191 Current prediction: Toyama / Japanese CORRECT\n",
      "64000 64.0 Loss: 2.1153 Current prediction: Daalen / French WRONG (Dutch)\n",
      "65000 65.0 Loss: 1.6833 Current prediction: Maruya / Portuguese WRONG (Japanese)\n",
      "66000 66.0 Loss: 0.2817 Current prediction: Tong / Vietnamese CORRECT\n",
      "67000 67.0 Loss: 1.9349 Current prediction: Han / Chinese WRONG (Vietnamese)\n",
      "68000 68.0 Loss: 2.5531 Current prediction: Neil / French WRONG (Irish)\n",
      "69000 69.0 Loss: 1.4790 Current prediction: Novak / Polish WRONG (Czech)\n",
      "70000 70.0 Loss: 3.4783 Current prediction: Roy / Korean WRONG (French)\n",
      "71000 71.0 Loss: 1.6065 Current prediction: Leroy / French CORRECT\n",
      "72000 72.0 Loss: 2.4886 Current prediction: Ricketts / Dutch WRONG (English)\n",
      "73000 73.0 Loss: 3.3876 Current prediction: Jacques / Portuguese WRONG (French)\n",
      "74000 74.0 Loss: 0.0175 Current prediction: Coghlan / Irish CORRECT\n",
      "75000 75.0 Loss: 0.4263 Current prediction: Paitakes / Greek CORRECT\n",
      "76000 76.0 Loss: 4.1425 Current prediction: Linart / French WRONG (Czech)\n",
      "77000 77.0 Loss: 0.8549 Current prediction: Kinsley / English CORRECT\n",
      "78000 78.0 Loss: 0.1015 Current prediction: Tokuda / Japanese CORRECT\n",
      "79000 79.0 Loss: 1.0206 Current prediction: Christie / Scottish CORRECT\n",
      "80000 80.0 Loss: 2.0827 Current prediction: Giolla / Spanish WRONG (Irish)\n",
      "81000 81.0 Loss: 2.3682 Current prediction: Gajos / Arabic WRONG (Polish)\n",
      "82000 82.0 Loss: 1.3743 Current prediction: Lin / Korean WRONG (Chinese)\n",
      "83000 83.0 Loss: 1.1550 Current prediction: Said / Arabic CORRECT\n",
      "84000 84.0 Loss: 3.9292 Current prediction: Fremut / French WRONG (Czech)\n",
      "85000 85.0 Loss: 0.1903 Current prediction: Thai / Vietnamese CORRECT\n",
      "86000 86.0 Loss: 1.3218 Current prediction: Zielinski / Russian WRONG (Polish)\n",
      "87000 87.0 Loss: 1.2516 Current prediction: Bruce / German WRONG (Scottish)\n",
      "88000 88.0 Loss: 1.5080 Current prediction: Handal / Scottish WRONG (Arabic)\n",
      "89000 89.0 Loss: 0.3173 Current prediction: Cucinotta / Italian CORRECT\n",
      "90000 90.0 Loss: 0.7199 Current prediction: Elworthy / English CORRECT\n",
      "91000 91.0 Loss: 1.2295 Current prediction: Cantu / Italian CORRECT\n",
      "92000 92.0 Loss: 0.2645 Current prediction: Ramaaker / Dutch CORRECT\n",
      "93000 93.0 Loss: 0.0050 Current prediction: Roosevelt / Dutch CORRECT\n",
      "94000 94.0 Loss: 2.3797 Current prediction: Muir / Chinese WRONG (Scottish)\n",
      "95000 95.0 Loss: 0.0371 Current prediction: Nakatoni / Japanese CORRECT\n",
      "96000 96.0 Loss: 0.8060 Current prediction: Leclerc / French CORRECT\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_21714/3980069095.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mcategory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_training_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategory_lines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_categories\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mcurrent_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_21714/1154674058.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(line_tensor, category_tensor)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/pytorch-train--hkbHhPz-py3.7/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_21714/2945133995.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mcombined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombined_to_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombined_to_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "current_loss = 0\n",
    "all_losses = []\n",
    "plot_steps, print_steps = 1000, 1000\n",
    "n_iters = 100000\n",
    "\n",
    "for i in range(n_iters):\n",
    "    category, line, category_tensor, line_tensor = random_training_example(category_lines, all_categories)\n",
    "    \n",
    "    output, loss = train(line_tensor, category_tensor)\n",
    "    current_loss += loss \n",
    "    \n",
    "    if (i+1) % plot_steps == 0:\n",
    "        all_losses.append(current_loss / plot_steps)\n",
    "        current_loss = 0\n",
    "        \n",
    "    if (i+1) % print_steps == 0:\n",
    "        guess = category_from_output(output)\n",
    "        correct = \"CORRECT\" if guess == category else f\"WRONG ({category})\"\n",
    "        print(f\"{i+1} {(i+1)/n_iters*100} Loss: {loss:.4f} Current prediction: {line} / {guess} {correct}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(all_losses)\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input_line):\n",
    "    print(f\"\\n> {input_line}\")\n",
    "    with torch.no_grad():\n",
    "        line_tensor = line_to_tensor(input_line)\n",
    "        \n",
    "        hidden = rnn.init_hidden()\n",
    "    \n",
    "        for i in range(line_tensor.size()[0]):\n",
    "            output, hidden = rnn(line_tensor[i], hidden)\n",
    "        \n",
    "        prediction = category_from_output(output)\n",
    "        print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> Mao\n",
      "Chinese\n"
     ]
    }
   ],
   "source": [
    "predict('Mao')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "11f370ec765c8da7f391d80d2c2a4b64c9f90ad987fa4753adc8ebf7b568460e"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 ('pytorch-train--hkbHhPz-py3.7')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
